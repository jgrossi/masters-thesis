%!TEX root = ../masters.tex

\chapter{Discussão / Trabalhos Futuros} % (fold)
\label{cha:conclusion}

Após todo o processo de pesquisa, de extração dos metadados pelas ferramentas analisadas e coleta de seus respectivos resultados, algumas considerações podem ser feitas, relativas aos objetivos propostos no início do trabalho.

Os resultados apresentados, de modo geral, foram inferiores às expectativas iniciais da pesquisa. As extrações não foram tão precisas quanto se imaginava. A grande diferença no leiaute dos elementos, presente no Corpus escolhido, realmente teve alto impacto nos resultados, principalmente no que diz respeito à extração dos autores e das referências.

Por outro lado, as ferramentas Cermine e CiteSeer obtiveram resultados para a extração do metadado ``título'' bem positivos, atingindo entre 83 e 89\% de precisão. Já a ferramenta CrossRef ficou bem abaixo do esperado, com 66.56\% de precisão apenas, porém acima da última colocada, a ferramenta ParsCit, que conseguiu extrair com sucesso apenas 15.17\% dos resultados dos ``títulos'', muito abaixo do esperado.

Para o metadado ``autores'' a ferramenta com maior precisão foi a Cermine, que atingiu 76.34\%, resultado próximo da segunda colocada, a CiteSeer, com 71.93\%. Já as demais ferramentas não obtiveram êxito na extração dos nomes dos autores, ficando abaixo dos 20\% de acerto.

Para a extração dos e-mails dos autores o resultado obtido, de modo geral, foi pior. A ferramenta que obteve maior êxito na extração deste metadado foi a Cermine, que conseguiu obter apenas 46.62\% de sucesso. Os resultados para este metadado obtidos pela ferramenta CiteSeer foram bem inferiores às expectativas, pois somente 4.17\% dos endereços foram extraídos com sucesso, resultado inferior ainda à ferramenta ParsCit, que extraiu 12.16\%. Como informado no capítulo ``Resultados'' (\autoref{cha:results}) a ferramenta CrossRef não conseguiu realizar a extração de nomes de autores, endereços de e-mails e do resumo, sendo estes resultados desconsiderados nesta sessão.

Em virtude da variação de leiaute do Corpus e da ausência de padronização da formatação do metadado ``resumo'' (\emph{abstract}), os resultados obtidos para este metadado superaram as expectativas. Exceto pela ferramenta CrossRef, todas as demais obtiveram resultados acima de 60\%, chegando a 86.83\% da ferramenta Cermine, a maior precisão encontrada. 

Esses resultados para ``resumo'' podem ser considerados positivos, principalmente em virtude de alguns artigos apresentarem o metadado de maneira bem diferente, com posicionamento bem divergente do habitual, inclusive, sem indícios de que ali se apresentava o resumo do artigo.

Outro ponto onde as expectativas não foram atingidas foi na extração das ``referências''. A ferramenta Cermine, mais uma vez, demonstrou-se mais precisa, alcançando 73.81\% de sucesso. A ferramenta CiteSeer, que utiliza a ParsCit para extração das referências, ao ser comparada com a própria ParsCit, produziu resultados pouco superiores, 54.75\% e 53.58\%, respectivamente. 

A diferença nos resultados se deve ao fato da ParsCit necessitar de arquivos \texttt{.txt} como forma de entrada de dados. No caso das extrações realizadas pela própria ferramenta, os arquivos \texttt{.txt} foram gerados pelo programa \texttt{pdftotext}, conforme detalhado no capítulo de ``Resultados'' (\autoref{cha:results}), diferentemente da ferramenta CiteSeer, que transforma o arquivo \texttt{.pdf} em \texttt{.txt} de sua própria maneira, causando então uma pequena divergência nos resultados gerais (1.17\%). 

Já a ferramenta CrossRef obteve apenas 20.06\% de precisão na extração das referências, o que era esperado em função de seus resultados com poucos detalhes, com apenas um único campo com todas as informações de cada referência.

Embora estes resultados da extração da ferramenta CrossRef não tenham sido positivos, um detalhe interessante que merece atenção é a forma como a ferramenta trata as referências. A ferramenta CrossRef permite que elas sejam comparadas com o banco de dados existente na URL \url{http://api.crossref.org}, possibilitando identificar exatamente quais artigos já foram catalogados pelo site, gerenciando seu conteúdo e relacionando-o a outros documentos. 

Para os artigos encontrados na base de dados do CrossRef é possível obter, inclusive, a descrição de cada um em formato BibTeX. Para este trabalho, em virtude dos poucos resultados obtidos, e por se tratar de um Corpus específico, esta funcionalidade não foi utilizada na extração ou na comparação dos resultados para esta ferramenta.

Em se tratando da separação dos resultados por área do conhecimento as ferramentas Cermine e CiteSeer obtiveram destaque, conseguindo 100\% de acertos em 4 (quatro) subáreas do conhecimento - Arquitetura e Urbanismo, Geologia, Fonoaudiologia, e Ciência da Computação -, porém para metadados diferentes.

A ferramenta Cermine acertou todos os títulos das áreas de Arquitetura e Urbanismo e Fonoaudiologia, além de 100\% dos nomes dos autores da área de Geologia. A ferramenta CiteSeer conseguiu precisão total na extração dos títulos de Arquitetura e Urbanismo, Ciência da Computação e Fonoaudiologia. 

Já a ferramenta CrossRef obteve melhor resultado na extração dos títulos dos artigos da área de Geologia, obtendo 97.62\% de precisão, superando as ferramentas CiteSeer e ParsCit, que obtiveram 73.77\% e 14.29\%, respectivamente.

Para a extração dos títulos dos artigos, os piores resultados foram encontrados nas áreas de Música (CiteSeer, com 49.02\%), Zootecnia (Cermine, com 49.95\% e CrossRef, com 32.05\%) e as áreas Ciências Biológicas (Zoologia) e Arquitetura e Urbanismo (ParsCit, com nenhum acerto).

A ferramenta Cermine se destacou na extração dos títulos em 8 (oito) subáreas do conhecimento - Arquitetura e Urbanismo, Ciências Biológicas (Zoologia), Enfermagem, Engenharia Mecânica, Fonoaudiologia, Geologia, História e Música -, obtendo resultados superiores a 99\%, o que foi considerado excelente. 

Para a extração dos nomes dos autores, os maiores destaques foram nas áreas de Geologia, Letras, Medicina Veterinária e Música, com resultados acima de 90\%. 

Na extração dos e-mails dos autores a ferramenta Cermine obteve resultados superiores a 85\% somente na área de Medicina Veterinária, seu melhor resultado para este metadado. Além disso, a ferramenta destacou-se na extração dos resumos em 5 (cinco) áreas, com resultados acima dos 98\%, e na extração das referências da área de Ciências Biológicas (Genética), onde obteve resultados acima de 96\% de precisão.

Já a ferramenta CiteSeer foi bem eficiente na extração dos títulos de 5 (cinco) subáreas: Arquitetura e Urbanismo, Ciência da Computação, Fonoaudiologia, História e Letras, com resultados superiores a 99\%. 

Para a extração dos nomes dos autores o resultado foi relevante em apenas 2 (duas) subáreas: Arquitetura e Urbanismo e Ciência da Informação, com precisão acima de 90\%. 

Já para os e-mails dos autores os resultados deixaram a desejar em 13 (treze) das 16 (dezesseis) subáreas, com 0\% de acerto, tendo resultados positivos apenas para as subáreas de Ciência da Computação, Ciências Biológicas (Genética) e Psicologia, porém com resultados abaixo de 29\% de acerto.

Para a extração dos resumos a ferramenta CiteSeer também se mostrou bem eficiente, com resultados acima de 90\% para 4 (quatro) subáreas: Arquitetura e Urbanismo, Ciência da Computação, Fonoaudiologia e Medicina Veterinária. 

Para as referências (utilizando o ParsCit) os resultados deixaram a desejar, com acertos abaixo de 72\%.

A ferramenta CrossRef mostrou resultados positivos apenas para a extração de títulos de artigos da subárea de Geologia, como já dito anteriormente, com 97.62\% de acerto, não tendo resultados considerados satisfatórios para as demais áreas. 

Para a extração das referências os resultados deixaram a desejar, com apenas 2 (duas) subáreas com precisão próxima de 30\%: Ciências Biológicas (Zoologia), com 32.72\% e Letras, com 32.58\%.

Por fim, a ferramenta ParsCit obteve resultados abaixo dos 38\% para os títulos, em todas as subáreas analisadas. 

O acerto dos nomes dos autores também foi baixo, onde os melhores resultados ficaram entre 43\% e 59\%, para as subáreas de Ciência da Computação, Letras e Música. 

Para os e-mails dos autores o melhor resultado foi para os artigos da subárea de Ciência da Computação, com 47.62\% de precisão. 

Já para o resumo dos artigos, os resultados foram um pouco melhores, acima de 70\% para 5 (cinco) subáreas do conhecimento. 

Os resultados para as referências foram semelhantes aos obtidos pela ferramenta CiteSeer, que utiliza a mesma ferramenta. Os 2 (dois) melhores resultados foram para as subáreas de Ciência da Computação e Psicologia, com precisão de 69.72\% e 68.84\%, respectivamente.

Para melhor visualização dos resultados, as Tabelas \ref{tab:areas-title-tools}, \ref{tab:areas-authors-tools}, \ref{tab:areas-emails-tools}, \ref{tab:areas-abstract-tools} e \ref{tab:areas-references-tools} apresentam as ferramentas que obtiveram os melhores resultados para cada subárea do conhecimento, separados por metadado. 

\begin{table}[h!]
    \caption{Melhores ferramentas para o metadado ``Título''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine/CiteSeer & 100\% \\ \hline
            Ciência da Computação & CiteSeer & 100\% \\ \hline
            Ciência da Informação & CiteSeer & 84.44\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 91.58\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 99.78\% \\ \hline
            Enfermagem & Cermine & 99.77\% \\ \hline
            Engenharia Civil & CiteSeer & 97.81\% \\ \hline
            Engenharia Mecânica & Cermine & 99.45\% \\ \hline
            Fonoaudiologia & Cermine/CiteSeer & 100\% \\ \hline
            Geologia & Cermine & 99.54\% \\ \hline
            História & CiteSeer & 99.53\% \\ \hline
            Letras & CiteSeer & 99.57\% \\ \hline
            Medicina Veterinária & Cermine/CiteSeer & 85.71\% \\ \hline
            Música & Cermine & 99.03\% \\ \hline
            Psicologia & CiteSeer & 94.93\% \\ \hline
            Zootecnia & CiteSeer & 71.43\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-title-tools}
\end{table}

\begin{table}[h!]
    \caption{Melhores ferramentas para o metadado ``Autores''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & CiteSeer & 96.89\% \\ \hline
            Ciência da Computação & CiteSeer & 83.75\% \\ \hline
            Ciência da Informação & CiteSeer & 99.50\% \\ \hline
            Ciências Biológicas (Genética) & CiteSeer & 83.15\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 73.16\% \\ \hline
            Enfermagem & CiteSeer & 52.82\% \\ \hline
            Engenharia Civil & Cermine & 76.34\% \\ \hline
            Engenharia Mecânica & Cermine & 75.97\% \\ \hline
            Fonoaudiologia & Cermine & 77.75\% \\ \hline
            Geologia & Cermine & 100\% \\ \hline
            História & Cermine & 89.29\% \\ \hline
            Letras & Cermine & 99.50\% \\ \hline
            Medicina Veterinária & Cermine & 91.11\% \\ \hline
            Música & Cermine & 90.61\% \\ \hline
            Psicologia & CiteSeer & 83.85\% \\ \hline
            Zootecnia & CiteSeer & 82.41\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-authors-tools}
\end{table}

\begin{table}[h!]
    \caption{Melhores ferramentas para o metadado ``E-mails''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 16.67\% \\ \hline
            Ciência da Computação & ParsCit & 47.62\% \\ \hline
            Ciência da Informação & Cermine/ParsCit & 28.57\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 50.00\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 42.86\% \\ \hline
            Enfermagem & Cermine & 16.67\% \\ \hline
            Engenharia Civil & Cermine/ParsCit & 37.50\% \\ \hline
            Engenharia Mecânica & Cermine & 58.33\% \\ \hline
            Fonoaudiologia & Cermine & 71.43\% \\ \hline
            Geologia & Cermine & 66.67\% \\ \hline
            História & Cermine & 50.00\% \\ \hline
            Letras & Cermine & 42.86\% \\ \hline
            Medicina Veterinária & Cermine & 85.71\% \\ \hline
            Música & Cermine & 66.67\% \\ \hline
            Psicologia & Cermine & 47.62\% \\ \hline
            Zootecnia & Cermine & 42.86\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-emails-tools}
\end{table}

\begin{table}[h!]
    \caption{Melhores ferramentas para o metadado ``Resumo''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 99.01\% \\ \hline
            Ciência da Computação & CiteSeer & 99.81\% \\ \hline
            Ciência da Informação & Cermine & 78.02\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 84.72\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 84.74\% \\ \hline
            Enfermagem & Cermine & 98.09\% \\ \hline
            Engenharia Civil & Cermine & 94.18\% \\ \hline
            Engenharia Mecânica & Cermine & 77.97\% \\ \hline
            Fonoaudiologia & Cermine & 98.13\% \\ \hline
            Geologia & Cermine & 53.66\% \\ \hline
            História & Cermine & 65.59\% \\ \hline
            Letras & Cermine & 82.10\% \\ \hline
            Medicina Veterinária & CiteSeer & 98.88\% \\ \hline
            Música & Cermine & 95.47\% \\ \hline
            Psicologia & Cermine & 92.53\% \\ \hline
            Zootecnia & Cermine & 87.40\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-abstract-tools}
\end{table}

\begin{table}[h!]
    \caption{Melhores ferramentas para o metadado ``Referências''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 82.67\% \\ \hline
            Ciência da Computação & Cermine & 77.25\% \\ \hline
            Ciência da Informação & CiteSeer & 55.56\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 96.11\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 72.28\% \\ \hline
            Enfermagem & Cermine & 81.69\% \\ \hline
            Engenharia Civil & Cermine & 56.23\% \\ \hline
            Engenharia Mecânica & Cermine & 82.87\% \\ \hline
            Fonoaudiologia & Cermine & 80.05\% \\ \hline
            Geologia & Cermine & 64.03\% \\ \hline
            História & CiteSeer & 63.81\% \\ \hline
            Letras & Cermine & 86.74\% \\ \hline
            Medicina Veterinária & Cermine & 80.05\% \\ \hline
            Música & Cermine & 68.50\% \\ \hline
            Psicologia & ParsCit & 68.84\% \\ \hline
            Zootecnia & Cermine & 81.99\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-references-tools}
\end{table}

Os resultados mostram que, para o Corpus escolhido, para o metadado ``Título'', a ferramenta Cermine foi superior, com 89.8\% de precisão, seguida da CiteSeer, com 83.55\%. O mesmo acontece para o metadado ``Autores'', onde a Cermine obteve os melhores resultados (76.34\%), seguida da CiteSeer, com 71.93\%.

Já para o metadado ``E-mails'' a Cermine foi sem dúvida a melhor, com 46.62\% de acertos, deixando uma grande diferença para a segunda colocada ParsCit, com apenas 12.66\%. Para o metadado ``Resumo'' a Cermine também se saiu melhor, com 86.83\% de precisão, e em segunda posição a CiteSeer com 75.81\%.

Por fim, para a extração do metadado ``Referências'' novamente a Cermine obteve o melhor resultado, acertando 73.81\% das extrações, seguida pela CiteSeer com 54.75\%.

\section{Contribuições}
\label{sec:contributions}

Como dito, os resultados coletados após as comparações ficaram abaixo das expectativas, exceto pelo metadado ``Título'', onde os números foram bem expressivos.

Em virtude da grande diferença no posicionamento visual dos elementos dos artigos do Corpus, os resultados foram muito variáveis, não sendo possível definir, com precisão, qual ferramenta se comporta melhor para uma determinada área ou subárea do conhecimento, mesmo que os resultados demonstrem, numericamente, o comportamento diferenciado de cada uma.

Estes resultados permitem aferir que as ferramentas de extração de metadados ainda tem espaço para evoluir, sendo necessários ajustes e adaptações para que uma maior quantidade de metadados seja extraída com sucesso. 

Além disso, algumas ferramentas apresentam melhores resultados em algumas subáreas do conhecimento, mas sem generalização possível, o que demandaria uma análise mais aprofundada dos resultados e uma seleção dos artigos mais específica.

Todo o código criado para a extração dos metadados e comparação das ferramentas está disponível em \url{http://github.com/jgrossi/met}, podendo ser utilizado para futuras pesquisas. É possível incluir novas ferramentas e metadados de maneira simplificada, reaproveitando todo o processo de comparação utilizado neste trabalho.

Ademais, todo o processo de comparação elaborado neste trabalho pode ser também reutilizado, permitindo inclusive o cálculo do Índice de Confiabilidade segundo os critérios adotados pelo autor. O índice permite a classificação de uma ferramenta segundo pesos definidos para cada metadado (\autoref{ssec:confiability-index}).

Por fim, pôde-se observar que o comportamento das técnicas de extração utilizadas pelas ferramentas é muito variável. Uma parcela dos resultados parece ser influenciada pelo modo de uso de cada técnica em cada ferramenta. Porém, deve-se levar em consideração a maneira como os algoritmos de cada técnica são implementados, bem como a maneira como os dados são tratados, tanto antes quanto depois da realização da extração. Assim, com base nos resultados numéricos apresentados, não é possível determinar qual técnica é mais aplicada para a extração de cada metadado.

\section{Trabalhos Futuros}
\label{sec:future-work}

Embora este trabalho tenha abrangido 16 (dezesseis) subáreas do conhecimento, com um total de 112 (cento e doze) artigos científicos analisados, a variedade real de formatos e leiautes vai muito além.

Poderia-se pensar em trabalhos mais detalhados para cada subárea do conhecimento, permitindo testar uma maior quantidade de artigos e padrões, de maneira a obter resultados mais próximos da realidade de cada área. Assim, seria possível identificar o comportamento destas ferramentas para cada área em específico, com um Corpus bem maior e variado, porém mais direcionado.

Um outro estudo possível seria a comparação por periódicos (revistas) ou bases de dados. Embora a diferenciação de leiaute para uma área do conhecimento seja muito ampla, geralmente existe uma padronização visual para uma determinada base, como é o caso da Elsevier \url{http://www.elsevier.com}, onde, independente da área do conhecimento, os artigos passam por uma padronização visual, permitindo adaptações mais precisas para as extrações destes documentos. 

Apesar de selecionadas as quatro ferramentas aqui comparadas, existem muitas outras ferramentas que merecem atenção, possibilitando um estudo de caso focado para uma determinada ferramenta, aprofundando muito mais suas características, funcionalidades e implementações, permitindo conclusões mais direcionadas e críticas mais precisas.

Seria ainda interessante estender a pesquisa considerando possíveis variações na extração manual dos metadados. Embora os dados tenham sido extraídos de maneira bem cautelosa é possível que as mesmas extrações, realizadas por pessoas diferentes, produzam resultados variados, o que poderia alterar em pequena proporção os resultados apresentados.

\section{Considerações Finais}
\label{sec:final-considerations}

Em virtude dos resultados apresentados e com base nas comparações realizadas, sugere-se que as ferramentas ainda tem espaço para evoluir, a fim de abranger um maior número de artigos e áreas do conhecimento.
 
Embora algumas ferramentas tenham se comportado melhor para alguns padrões visuais, não é possível estabelecer uma regra ou afirmação com base nos resultados encontrados.

Além disso, dadas as fragilidades das ferramentas testadas, sugere-se que o desenvolvimento de uma nova solução poderia ser de interesse, possibilitando uma análise mais profunda das necessidades de cada metadado, bem como das técnicas mais adequadas em cada aplicação.

