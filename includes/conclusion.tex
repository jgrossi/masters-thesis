%!TEX root = ../masters.tex

\chapter{Discussão / Trabalhos Futuros} % (fold)
\label{cha:conclusion}

% Analisar os objetivos gerais e específicos e explicar como o desenvolvimento ajudou a chegar em cada um destes objetivos

    % O objetivo da pesquisa é comparar ferramentas de extração de metadados em artigos científicos, identificando também suas melhores aplicações, com base em um conjunto de documentos pré-selecionados para testes, dos mais diversos padrões e de diversas áreas do conhecimento.

    % Com efeito, esta identificação permite que resultados sejam comparados e confrontados, para decidir qual ferramenta é melhor utilizada para cada padrão visual, abrangendo um conjunto cada vez maior de dados e tendo resultados cada vez mais precisos.

    % Com base na diferenciação dos \textit{layouts} de artigos científicos, este trabalho visa identificar também pontos em que as ferramentas de extração de metadados necessitam de adaptações por parte de seus usuários e desenvolvedores, garantindo assim, uma cobertura mais abrangente dos artigos científicos. Além disso, com base nos resultados coletados, pode-se identificar qual ferramenta é melhor aplicada para cada tipo distinto de metadado.

    % Acredita-se que os padrões de extração existentes hoje são, de maneira geral, insuficientes para suprir todos os \emph{layouts} de artigos existentes, limitando a apenas uma pequena parcela destes, dentro de um padrão visual específico.

Após todo o processo de pesquisa, de extração dos metadados pelas ferramentas analisadas e seus respectivos resultados, diversas conclusões podem ser feitas objetivando cumprir com os objetivos propostos no início do trabalho.

Os resultados apresentados, de modo geral, foram inferiores às expectativas do próprio autor, uma vez que as extrações não foram tão precisas quanto se imaginava. A diversidade visual presente no Corpus escolhido realmente teve alto impacto nos resultados, principalmente no que se diz respeito à extração dos autores e das referências.

% Falar dos resultados por ferramentas de maneira geral primeiro

De modo geral, as ferramentas Cermine e CiteSeer obtiveram um resultado para a extração do metadado ``título'' positivo, ficando entre 83 e 89\% de precisão. Já a ferramenta CrossRef ficou bem abaixo do esperado, com 66.56\% de precisão apenas, porém acima da última colocada, a ferramenta ParsCit, que conseguiu extrair com sucesso apenas 15.17\% dos resultados dos ``títulos'', muito abaixo do esperado.

Para o metadado ``autores'' a ferramenta com maior precisão foi a Cermine, que atingiu 76.34\%, resultado próximo da segunda colocada, a CiteSeer, com 71.93\%. Já as demais ferramentas não obtiveram êxito na extração dos nomes dos autores, ficando abaixo dos 20\% de acerto.

Já para a extração dos e-mails dos autores o resultado obtido, de modo geral, foi pior. A ferramenta que obteve maior êxito na extração deste metadado foi a Cermine, que conseguiu obter apenas 46.62\% de sucesso. Os resultados para este metadado obtidos pela ferramenta CiteSeer foram bem inferiores às expectativas, pois somente 4.17\% dos endereços foram extraídos com sucesso, resultado inferior ainda à ferramenta ParsCit, que extraiu 12.16\%. Como informado no capítulo ``Resultados'' (\autoref{cha:results}) a ferramenta CrossRef não conseguiu realizar a extração de nomes de autores, endereços de e-mails e do resumo, sendo estes resultados desconsiderados nesta sessão.

Em virtude da grande diferenciação visual, inclusive pela ausência de uma padronização para apresentação do metadado ``resumo'' \emph{abstract}, os resultados obtidos superaram as expectativas do autor, visto que, exceto pela ferramenta CrossRef, todas as demais obtiveram resultados acima de 60\%, chegando a 86.83\% da ferramenta Cermine. Estes resultados, embora ainda abaixo do considerado ``ideal'' foram positivos, principalmente em virtude de alguns artigos apresentarem este metadado de formas bem peculiares, com posicionamento bem diferente do habitual e, inclusive, sem indícios de que ali apresentava-se o resumo do artigo.

Outro ponto onde as expectativas do autor não foram atingidas foi na extração das ``referências''. A ferramenta Cermine, mais uma vez, demonstrou-se mais precisa, conquistando 73.81\% de sucesso. A ferramenta CiteSeer, que utiliza da ParsCit para extração das referências, ao ser comparada com a própria ParsCit, produziu resultados ou pouco superiores, 54.75\% e 53.58\%, respectivamente. A diferença nos resultados se deve pelo fato da ferramenta ParsCit necessitar de arquivos \texttt{.txt} como entrada de dados. No caso das extrações realizadas pela própria ferramenta, os arquivos \texttt{.txt} foram gerados pelo programa \texttt{pdftotext}, conforme detalhado no capítulo de ``Resultados'' (\autoref{cha:results}), diferentemente da ferramenta CiteSeer, que transforma o arquivo \texttt{.pdf} em \texttt{.txt} de sua própria maneira, causando então uma pequena divergência nos resultados (1.17\%). 

Já a ferramenta CrossRef obteve apenas 20.06\% de precisão na extração das referências, o que era esperado em função de sua extração com poucos detalhes, com apenas um único campo com todas as informações de cada referência. Embora os resultados da extração não tenham sido positivos, um detalhe interessante que merece uma atenção, é a forma como esta ferramenta trata as referências. A ferramenta permite que elas sejam comparadas com o banco de dados do \url{http://api.crossref.org}, permitindo identificar exatamente quais artigos já foram catalogadas pelo site, gerando um grande controle sobre o conteúdo. Para os artigos encontrados no site é possível obter, inclusive, a descrição em formato BibTeX, com todas as informações relevantes para uma correta citação. Para este trabalho, em virtude dos poucos resultados obtidos, esta funcionalidade não foi utilizada na extração.

% Falar das melhores ferramentas para cada área do conhecimento

Em se tratando da separação dos resultados por área do conhecimento as ferramentas Cermine e CiteSeer obtiveram destaque, conseguindo 100\% de acertos em 3 subáreas do conhecimento, porém para metadados diferentes. A ferramenta Cermine acertou todos os títulos das áreas de Arquitetura e Urbanismo e Fonoaudiologia, além de 100\% dos nomes dos autores da área de Geologia. Já a ferramenta CiteSeer conseguiu precisão total na extração dos títulos de Arquitetura e Urbanismo, Ciência da Computação e Fonoaudiologia. Já a ferramenta CrossRef obteve melhor resultado na extração dos títulos dos artigos da área de Geologia, obtendo 97.62\% de precisão, superando a ferramenta CiteSeer e ParsCit, que obtiveram 73.77\% e 14.29\% respectivamente.

Para a extração dos títulos dos artigos, os piores resultados foram encontrados nas áreas de Música (CiteSeer, com 49.02\%), Zootecnia (Cermine, com 49.95\% e CrossRef, com 32.05\%) e as áreas Ciências Biológicas (Zoologia) e Arquitetura e Urbanismo (ParsCit, com nenhum acerto).

A ferramenta Cermine se destacou na extração de títulos de 8 (oito) subáreas do conhecimento - Arquitetura e Urbanismo, Ciências Biológicas (Zoologia), Enfermagem, Engenharia Mecânica, Fonoaudiologia, Geologia, História e Música -, obtendo resultados superiores a 99\%, o que é considerado excelente. 

Para os autores, seus maiores destaques foram nas áreas de Geologia, Letras, Medicina Veterinária e Música, com resultados acima de 90\%. Na extração dos e-mails dos autores a ferramente obteve resultados superiores a 85\% somente na área de Medicina Veterinária, seu melhor resultado para este metadado. Além disso, a ferramenta se destacou na extração dos resumos em 5 (cinco) áreas, com resultados acima dos 98\%, e na extração das referências de Ciências Biológicas (Genética), que obteve acima de 96\% de precisão.

Já a ferramenta CiteSeer demonstrou bem eficiente na extração dos títulos de 5 (cinco) subáreas: Arquitetura e Urbanismo, Ciência da Computação, Fonoaudiologia, História e Letras, com resultados superiores a 99\%. Para a extração dos nomes dos autores o resultado foi positivo em apenas 2 (duas) subáreas: Arquitetura e Urbanismo e Ciência da Informação, com precisão acima de 90\%. Já para os e-mails dos autores os resultados foram negativos para 13 (treze) das 16 (dezesseis) subáreas, com 0\% de acerto, tendo resultados positivos apenas para as subáreas de Ciência da Computação, Ciências Biológicas (Genética) e Psicologia, porém com resultados abaixo dos 29\% de acerto.

Para a extração dos resumos a ferramenta CiteSeer demonstrou bem eficiente também, com resultados acima dos 90\% para 4 (quatro) subáreas: Arquitetura e Urbanismo, Ciência da Computação, Fonoaudiologia e Medicina Veterinária. Para as referências (onde o CiteSeer utiliza do ParsCit) os resultados deixaram a desejar, com resultados abaixo dos 72\%.

A ferramenta CrossRef se demonstrou positiva apenas para a extração de títulos de Geologia, como já dito anteriormente, com 97.62\% de precisão, não tendo resultados satisfatórios para as demais áreas. Já para as referências os resultados também deixaram a desejar, com apenas 2 (duas) subáreas com precisão próxima de 30\%: Ciências Biológicas (Zoologia), com 32.72\% e Letras, com 32.58\%.

Por fim, a ferramenta ParsCit obteve resultados abaixo dos 38\% para os títulos, em todas as subáreas. O acerto dos nomes dos autores também foi baixo, onde os melhores resultados ficaram entre 43\% e 59\%, para as subáreas de Ciência da Computação, Letras e Música. Para os e-mails dos autores o melhor resultado foi para Ciência da Computação, com 47.62\% de precisão. Já para o resumo dos artigos os resultados foram um pouco melhores, com resultados acima de 70\% para 5 (cinco) subáreas. Os resultados para as referências foram semelhantes aos obtidos pela ferramenta CiteSeer, por se utilizar da mesma ferramenta, onde os 2 (dois) melhores resultados foram para as subáreas de Ciência da Computação e Psicologia, com precisão de 69.72\% e 68.84\%, respectivamente.

Visando uma melhor visualização dos resultados, as Tabelas \ref{tab:areas-title-tools}, \ref{tab:areas-authors-tools}, \ref{tab:areas-emails-tools}, \ref{tab:areas-abstract-tools} e \ref{tab:areas-references-tools} apresentam as ferramentas que obtiveram os melhores resultados para cada subárea do conhecimento, separado por cada metadado. 

\begin{table}
    \caption{Melhores ferramentas para o metadado ``Título''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine/CiteSeer & 100\% \\ \hline
            Ciência da Computação & CiteSeer & 100\% \\ \hline
            Ciência da Informação & CiteSeer & 84.44\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 91.58\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 99.78\% \\ \hline
            Enfermagem & Cermine & 99.77\% \\ \hline
            Engenharia Civil & CiteSeer & 97.81\% \\ \hline
            Engenharia Mecânica & Cermine & 99.45\% \\ \hline
            Fonoaudiologia & Cermine/CiteSeer & 100\% \\ \hline
            Geologia & Cermine & 99.54\% \\ \hline
            História & CiteSeer & 99.53\% \\ \hline
            Letras & CiteSeer & 99.57\% \\ \hline
            Medicina Veterinária & Cermine/CiteSeer & 85.71\% \\ \hline
            Música & Cermine & 99.03\% \\ \hline
            Psicologia & CiteSeer & 94.93\% \\ \hline
            Zootecnia & CiteSeer & 71.43\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-title-tools}
\end{table}

\begin{table}
    \caption{Melhores ferramentas para o metadado ``Autores''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & CiteSeer & 96.89\% \\ \hline
            Ciência da Computação & CiteSeer & 83.75\% \\ \hline
            Ciência da Informação & CiteSeer & 99.50\% \\ \hline
            Ciências Biológicas (Genética) & CiteSeer & 83.15\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 73.16\% \\ \hline
            Enfermagem & CiteSeer & 52.82\% \\ \hline
            Engenharia Civil & Cermine & 76.34\% \\ \hline
            Engenharia Mecânica & Cermine & 75.97\% \\ \hline
            Fonoaudiologia & Cermine & 77.75\% \\ \hline
            Geologia & Cermine & 100\% \\ \hline
            História & Cermine & 89.29\% \\ \hline
            Letras & Cermine & 99.50\% \\ \hline
            Medicina Veterinária & Cermine & 91.11\% \\ \hline
            Música & Cermine & 90.61\% \\ \hline
            Psicologia & CiteSeer & 83.85\% \\ \hline
            Zootecnia & CiteSeer & 82.41\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-authors-tools}
\end{table}

\begin{table}
    \caption{Melhores ferramentas para o metadado ``E-mails''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 16.67\% \\ \hline
            Ciência da Computação & ParsCit & 47.62\% \\ \hline
            Ciência da Informação & Cermine/ParsCit & 28.57\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 50.00\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 42.86\% \\ \hline
            Enfermagem & Cermine & 16.67\% \\ \hline
            Engenharia Civil & Cermine/ParsCit & 37.50\% \\ \hline
            Engenharia Mecânica & Cermine & 58.33\% \\ \hline
            Fonoaudiologia & Cermine & 71.43\% \\ \hline
            Geologia & Cermine & 66.67\% \\ \hline
            História & Cermine & 50.00\% \\ \hline
            Letras & Cermine & 42.86\% \\ \hline
            Medicina Veterinária & Cermine & 85.71\% \\ \hline
            Música & Cermine & 66.67\% \\ \hline
            Psicologia & Cermine & 47.62\% \\ \hline
            Zootecnia & Cermine & 42.86\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-emails-tools}
\end{table}

\begin{table}
    \caption{Melhores ferramentas para o metadado ``Resumo''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 99.01\% \\ \hline
            Ciência da Computação & CiteSeer & 99.81\% \\ \hline
            Ciência da Informação & Cermine & 78.02\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 84.72\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 84.74\% \\ \hline
            Enfermagem & Cermine & 98.09\% \\ \hline
            Engenharia Civil & Cermine & 94.18\% \\ \hline
            Engenharia Mecânica & Cermine & 77.97\% \\ \hline
            Fonoaudiologia & Cermine & 98.13\% \\ \hline
            Geologia & Cermine & 53.66\% \\ \hline
            História & Cermine & 65.59\% \\ \hline
            Letras & Cermine & 82.10\% \\ \hline
            Medicina Veterinária & CiteSeer & 98.88\% \\ \hline
            Música & Cermine & 95.47\% \\ \hline
            Psicologia & Cermine & 92.53\% \\ \hline
            Zootecnia & Cermine & 87.40\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-abstract-tools}
\end{table}

\begin{table}
    \caption{Melhores ferramentas para o metadado ``Referências''}
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \hline 
            \textbf{Subáreas do Conhecimento} & \textbf{Ferramentas} & \textbf{Precisão} \\ 
            \hline 
            Arquitetura e Urbanismo & Cermine & 82.67\% \\ \hline
            Ciência da Computação & Cermine & 77.25\% \\ \hline
            Ciência da Informação & CiteSeer & 55.56\% \\ \hline
            Ciências Biológicas (Genética) & Cermine & 96.11\% \\ \hline
            Ciências Biológicas (Zoologia) & Cermine & 72.28\% \\ \hline
            Enfermagem & Cermine & 81.69\% \\ \hline
            Engenharia Civil & Cermine & 56.23\% \\ \hline
            Engenharia Mecânica & Cermine & 82.87\% \\ \hline
            Fonoaudiologia & Cermine & 80.05\% \\ \hline
            Geologia & Cermine & 64.03\% \\ \hline
            História & CiteSeer & 63.81\% \\ \hline
            Letras & Cermine & 86.74\% \\ \hline
            Medicina Veterinária & Cermine & 80.05\% \\ \hline
            Música & Cermine & 68.50\% \\ \hline
            Psicologia & ParsCit & 68.84\% \\ \hline
            Zootecnia & Cermine & 81.99\% \\ \hline
        \end{tabular}
    \end{center}
    \label{tab:areas-references-tools}
\end{table}

Assim, de modo geral, podemos concluir que para este Corpus escolhido, com base nos critérios adotados neste trabalho, para o metadado ``Título'' a ferramenta que obteve os melhores resultados de extração foi a Cermine, com 89.8\% de precisão, seguida da CiteSeer, com 83.55\%. O mesmo acontece para o metadado ``Autores'', onde a ferramenta Cermine obteve os melhores resultados (76.34\%) seguida da CiteSeer, com 71.93\%.

Já para o metadado ``E-mails'' a ferramenta Cermine foi sem sombra de dúvidas a melhor, com 46.62\%, deixando uma larga diferença para a segunda colocada ParsCit, com apenas 12.66\%. Para o metadado ``Resumo'' a Cermine também se saiu melhor, com 86.83\%, tendo em segunda posição a CiteSeer com 75.81\%.

Por fim, para a extração do metadado ``Referências'' novamente a ferramenta Cermine obteve o melhor resultado, com precisão de 73.81\% dos resultados, seguida da ferramenta CiteSeer com 54.75\%.

% Apresentar os pontos positivos e negativos do trabalho também
% Lições aprendidas

% "... o problema descrito na seção X foi resolvido como demonstrado nas sessões y a z, em que foi desenvolvido um algoritmo/método/abordagem etc para tratar as situações mencionadas.

\section{Contribuições}
\label{sec:contributions}

Os resultados coletados após estas comparações foram abaixo das expectativas do autor, exceto pelo metadado ``Título'', onde os números foram mais expressivos.

Em virtude da grande diferenciação visual do Corpus escolhido os resultados foram muito variáveis, não sendo possível definir, com precisão, qual ferramenta se comporta melhor para uma determinada área ou subárea do conhecimento, embora os resultados demonstrem, numericamente, o comportamento diferenciado de cada uma.

Estes resultados permitem aferir que as ferramentas de extração de metadados ainda precisam evoluir, sendo necessários ajustes e adaptações para que uma maior quantidade de dados seja extraída com sucesso. Além disso, algumas ferramentas tendem a ser melhores em algumas subáreas do conhecimento, mas sem generalização, possibilitando uma análise posterior mais detalhada e mais aprofundada.

\section{Trabalhos Futuros}
\label{sec:future-work}

% Falar sobre oportunidades de pesquisa nesta área, que o autor não conseguiu averiguar, mas serve de dicas para os próximos interessados

% Futuras contribuições ao conhecimento com mais ênfase do que futuras contribuições às ferramentas, protótipos, etc, que eventualmente possa, ser desenvolvidas

Embora tenha-se abrangido 16 (dezesseis) subáreas do conhecimento, com um total de 112 (cento e doze) artigos científicos, a variedade de formados e layouts encontrada vai muito mais além desta análise, merecendo um trabalho mais detalhado para cada subárea do conhecimento.

Um ponto interessante de análise seria um trabalho de comparação para artigos de uma área do conhecimento específica, como Engenharia, por exemplo, onde um maior número de artigos desta área seria testado, objetivando identificar o comportamento destas ferramentas para esta área em específico somente, com um Corpus bem maior e variado, porém mais direcionado.

% Comparação por revista

Um outro estudo interessante seria a comparação por revistas ou bases de dados. Embora a diferenciação visual para uma área do conhecimento seja muito ampla, geralmente existe uma padronização visual para uma determinada base, como é o caso da Elsevier \url{http://www.elsevier.com}, onde, independente da área do conhecimento, os artigos passam por uma padronização visual. Assim, um estudo sobre o comportamento de ferramentas de extração de metadados em artigos científicos, focado para estas bases, traria também um relativo ganho de conhecimento para a comunidade científica.

Além disso, apesar de selecionadas as quatro ferramentas aqui comparadas, existem muitas outras ferramentas que merecem atenção, possibilitando um estudo de caso focado para uma determinada ferramenta, aprofundando muito mais suas características e funcionalidades, permitindo conclusões mais direcionadas e inclusive críticas mais precisas quanto aos resultados por ela apresentados.


\section{Considerações Finais}
\label{sec:final-considerations}
